{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Useless"
      ],
      "metadata": {
        "id": "KUGegazFDhUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-fOoUp5ZfnJ",
        "outputId": "7acd1a61-d124-430c-99b9-ef54e8e8444f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjJsjJQIoQcB",
        "outputId": "9a4bba00-c654-40bd-e208-f95f023fb4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dda4220\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7iVwSq8FbTF",
        "outputId": "d6ae2ad0-1fad-4877-ec05-1ebb12265f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: mapcalc in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers timm pycocotools mapcalc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gIJ0QQNZeUb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHqVsUJ5-A4S"
      },
      "source": [
        "# YOLO-tiny by Hustvl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268,
          "referenced_widgets": [
            "aea93a4ab8b04d8f86c188d02c4e4add",
            "2fa2c766b41c4cd48493673b1db8583c",
            "fa39a12f34a54c49ac06965714e77198",
            "1747fbe6f82a4e0a810f54559f246ed3",
            "f32efdfdd37b4843bf426febdaac3d90",
            "b016daf67bc14d59bf37ad45735e865d",
            "e40564769b92434abb825a83ac811097",
            "75fad9f08874482d97330066fa1c037d",
            "cff9ef37353c44f5821d03c58aa6527a",
            "67edc3ff20b84233a3b996008d2bf5a9",
            "75c9d26e85d54ef480b7f67d15765a5d",
            "e37c2f3c6a0542be88cbf7d3a1d361d5",
            "0fe2332b0b16415292f099bc1193fbd1",
            "21669dd0d5454956a1c27086551726fb",
            "2a47e10d9fea42baaff52e8c9620b780",
            "2e151d67436247e9bef9ddd9d4ecac7d",
            "54f6b3696f304c59ba217d0ae34b8310",
            "6142c1f5f1e14672ba5787a10095764e",
            "71f8bfd34aa1491c8793d75731ed9a4a",
            "312de1127db54816aa03e9388a3cfcbb",
            "28e0ddf18d69434084a6ca8e7051b248",
            "62e7a146254d4770af584a0e408f13b7",
            "a05a5cf83d96474aafbe98238a308ec9",
            "2807487061714ef7be36b5e603033022",
            "52561bc49e1d4e9da403a1e58016108c",
            "47bf388637fc4730a3f39e0039b71a30",
            "5570ac7f0a894ebe9fe0676501c047c7",
            "6028974c7d1641189825e8937bd7b4b1",
            "c79c635fe6a940f5883bd39093f37f45",
            "a7b465c30427449c8ead21b880a55260",
            "0feeab7a1c5847d9a232fa5d92524118",
            "c21832acae4e4900bff9619e45a9bfa0",
            "5ded7f2574b7488ea9d3a3a7a72d9aee"
          ]
        },
        "id": "9HadekLMFUrD",
        "outputId": "f9379d37-e1f6-4d81-a881-234918f37475"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.13k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aea93a4ab8b04d8f86c188d02c4e4add"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/26.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e37c2f3c6a0542be88cbf7d3a1d361d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)rocessor_config.json:   0%|          | 0.00/275 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a05a5cf83d96474aafbe98238a308ec9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected remote with confidence 0.994 at location [46.96, 72.61, 181.02, 119.73]\n",
            "Detected remote with confidence 0.975 at location [340.66, 79.19, 372.59, 192.65]\n",
            "Detected cat with confidence 0.984 at location [12.27, 54.25, 319.42, 470.99]\n",
            "Detected remote with confidence 0.922 at location [41.66, 71.96, 178.7, 120.33]\n",
            "Detected cat with confidence 0.914 at location [342.34, 21.48, 638.64, 372.46]\n"
          ]
        }
      ],
      "source": [
        "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
        "from PIL import Image\n",
        "import torch\n",
        "import requests\n",
        "\n",
        "\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "model = YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
        "image_processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
        "\n",
        "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# model predicts bounding boxes and corresponding COCO classes\n",
        "logits = outputs.logits\n",
        "bboxes = outputs.pred_boxes\n",
        "\n",
        "\n",
        "# print results\n",
        "target_sizes = torch.tensor([image.size[::-1]])\n",
        "results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
        "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "    box = [round(i, 2) for i in box.tolist()]\n",
        "    print(\n",
        "        f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
        "        f\"{round(score.item(), 3)} at location {box}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgpCwhgd0ZHR",
        "outputId": "a638261f-fdbe-4b32-b0ee-6849a733ad36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17125"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "len(os.listdir(voc2012_image_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVtQyxgAFsSI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suXrMN5-HwMN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIfvjoYGYjX-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU5sIYl8YNGd"
      },
      "source": [
        "# Faster R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWDGMkwEHfj-"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScDtrzBLYf10",
        "outputId": "5b23ae58-b684-4fe3-c4a8-a54b8d8b783c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.0.0+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.datasets import VOCDetection\n",
        "from torchvision import transforms\n",
        "from torchvision.ops import box_iou\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms import functional as F\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, image, target):\n",
        "        image = F.to_tensor(image)\n",
        "        return image, target\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.to(device)\n",
        "\n",
        "transform = ToTensor()\n",
        "from torchvision.datasets import VOCDetection\n",
        "trainval_data = VOCDetection(root=\".\", image_set=\"trainval\", download=True, transforms=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "2AMDaQ3aqZ3E",
        "outputId": "68ea72ca-6bce-488e-b992-7de5dfb8dd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./VOCtrainval_11-May-2012.tar\n",
            "Extracting ./VOCtrainval_11-May-2012.tar to .\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-97ff2e50508b>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrainval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOCDetection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"trainval\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/voc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, year, image_set, download, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting {archive} to {extract_root}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_finished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mextract_archive\u001b[0;34m(from_path, to_path, remove_finished)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ARCHIVE_EXTRACTORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marchive_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m     \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremove_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_extract_tar\u001b[0;34m(from_path, to_path, compression)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_extract_tar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"r:{compression[1:]}\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                 \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0o700\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0;31m# Do not set_attrs directories, as we will do that further down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0m\u001b[1;32m   2046\u001b[0m                          numeric_owner=numeric_owner)\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2086\u001b[0;31m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0m\u001b[1;32m   2087\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m                                  numeric_owner=numeric_owner)\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m         \u001b[0mbufsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopybufsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mbltn_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjLKLVfPYMro"
      },
      "outputs": [],
      "source": [
        "VOC_CLASSES = [\n",
        "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
        "    \"bus\", \"car\", \"cat\", \"chair\", \"cow\",\n",
        "    \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
        "    \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
        "]\n",
        "\n",
        "def preprocess_targets(targets):\n",
        "    new_targets = []\n",
        "    for target in targets:\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for obj in target[\"annotation\"][\"object\"]:\n",
        "            bbox = obj[\"bndbox\"]\n",
        "            box = [int(bbox[\"xmin\"]), int(bbox[\"ymin\"]), int(bbox[\"xmax\"]), int(bbox[\"ymax\"])]\n",
        "            boxes.append(box)\n",
        "            labels.append(VOC_CLASSES.index(obj[\"name\"]))\n",
        "        new_targets.append({\"boxes\": torch.tensor(boxes, dtype=torch.float32), \"labels\": torch.tensor(labels, dtype=torch.int64)})\n",
        "    return new_targets\n",
        "\n",
        "def calculate_image_precision(pred_boxes, true_boxes, thresholds = (0.5, 0.55, 0.6, 0.65, 0.7, 0.75)):\n",
        "    precisions = []\n",
        "    for threshold in thresholds:\n",
        "        fp = tp = 0\n",
        "        for pred_box in pred_boxes:\n",
        "            ious = box_iou(true_boxes, pred_box[0].unsqueeze(0))\n",
        "            if torch.any(ious >= threshold):\n",
        "                tp += 1\n",
        "            else:\n",
        "                fp += 1\n",
        "        if (tp+fp) == 0:\n",
        "            precision = 0\n",
        "        else:\n",
        "            precision = tp / (tp + fp)\n",
        "        precisions.append(precision)\n",
        "    return 1 - sum(precisions) / len(precisions)\n",
        "    \n",
        "\n",
        "train_size = int(0.8 * len(trainval_data))\n",
        "val_size = len(trainval_data) - train_size\n",
        "train_data, val_data = random_split(trainval_data, [train_size, val_size])\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    val_data, batch_size=2, shuffle=True, num_workers=4,\n",
        "    collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    results = []\n",
        "    image_precisions = []\n",
        "    for images, targets in test_loader:\n",
        "        images = [image.to(device) for image in images]\n",
        "        targets = preprocess_targets(targets)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        output = model(images)\n",
        "\n",
        "        preds = []\n",
        "        for box, score in zip(output[0]['boxes'], output[0]['scores']):\n",
        "            preds.append((box, score))\n",
        "        image_precision = calculate_image_precision(preds, targets[0]['boxes'])\n",
        "        image_precisions.append(image_precision)\n",
        "\n",
        "    mAP = sum(image_precisions) / len(image_precisions)\n",
        "    print(f'mAP: {mAP}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WhR9OToHhqh"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIqPhhT1HOqd"
      },
      "outputs": [],
      "source": [
        "num_classes = 21\n",
        "# Get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, targets in train_loader:\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = preprocess_targets(targets)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            \n",
        "            # Forward pass\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            \n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    try:\n",
        "        return tuple(zip(*batch))\n",
        "    except Exception as e:\n",
        "        print(f\"Exception while processing batch: {e}\")\n",
        "        for item in batch:\n",
        "            try:\n",
        "                # Attempt to process each item in the batch individually\n",
        "                tuple(zip(*item))\n",
        "            except Exception as e:\n",
        "                print(f\"Exception for item {item}: {e}\")\n",
        "        # Reraise the original exception\n",
        "        raise e\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     train_data, batch_size=2, shuffle=True, num_workers=4,\n",
        "#     collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=2, shuffle=True, num_workers=4,\n",
        "    collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, optimizer, num_epochs=2)\n",
        "\n",
        "# After training, save the model for future use or evaluation\n",
        "torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn_finetuned.pth')\n",
        "\n",
        "# Now evaluate the model with the evaluation code you have already written\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Run the model on the test data and gather the results\n",
        "    results = []\n",
        "    image_precisions = []\n",
        "    for images, targets in test_loader:\n",
        "        images = [image.to(device) for image in images]\n",
        "        targets = preprocess_targets(targets)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        output = model(images)\n",
        "\n",
        "        preds = []\n",
        "        for box, score in zip(output[0]['boxes'], output[0]['scores']):\n",
        "            preds.append((box, score))\n",
        "        image_precision = calculate_image_precision(preds, targets[0]['boxes'])\n",
        "        image_precisions.append(image_precision)\n",
        "\n",
        "    # Compute mean Average Precision (mAP)\n",
        "    mAP = sum(image_precisions) / len(image_precisions)\n",
        "    print(f'mAP: {mAP}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYestC7eHOoF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO-LELitHkUb"
      },
      "source": [
        "# YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lV_MVlRk-WrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcN7ywv2HOlS"
      },
      "outputs": [],
      "source": [
        "%pip install gluoncv mxnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74MahAzb-Yvg",
        "outputId": "f11e1b0b-2ec3-4996-8e5c-c23a5ec2c747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import VOCDetection\n",
        "trainval_data = VOCDetection(root=\".\", image_set=\"trainval\", download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7yHpmEE8Y4d",
        "outputId": "597a8814-d41f-4f02-9052-128689718f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to ./VOCtrainval_11-May-2012.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1999639040/1999639040 [01:25<00:00, 23317764.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./VOCtrainval_11-May-2012.tar to .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCghBpbaHOhi"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pickle\n",
        "import os\n",
        "from os import listdir, getcwd\n",
        "from os.path import join\n",
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "classes = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',\n",
        "        'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'] # 划分的类别，依实际情况而定\n",
        "# classes=[\"ball\"]\n",
        "\n",
        "TRAIN_RATIO = 80  # 训练集与数据集划分的比例\n",
        "\n",
        "\n",
        "def clear_hidden_files(path):\n",
        "    dir_list = os.listdir(path)\n",
        "    for i in dir_list:\n",
        "        abspath = os.path.join(os.path.abspath(path), i)\n",
        "        if os.path.isfile(abspath):\n",
        "            if i.startswith(\"._\"):\n",
        "                os.remove(abspath)\n",
        "        else:\n",
        "            clear_hidden_files(abspath)\n",
        "\n",
        "\n",
        "def convert(size, box): # 边界框的转换\n",
        "    dw = 1. / size[0]\n",
        "    dh = 1. / size[1]\n",
        "    x = (box[0] + box[1]) / 2.0\n",
        "    y = (box[2] + box[3]) / 2.0\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return (x, y, w, h)\n",
        "\n",
        "\n",
        "def convert_annotation(image_id):\n",
        "    in_file = open('./VOCdevkit/VOC2012/Annotations/%s.xml' % image_id) # xml路径\n",
        "    out_file = open('./VOCdevkit/VOC2012/YOLOLabels/%s.txt' % image_id, 'w')\n",
        "    tree = ET.parse(in_file)\n",
        "    root = tree.getroot()\n",
        "    size = root.find('size')\n",
        "    w = int(size.find('width').text)\n",
        "    h = int(size.find('height').text)\n",
        "\n",
        "    for obj in root.iter('object'):\n",
        "        difficult = obj.find('difficult').text\n",
        "        cls = obj.find('name').text\n",
        "        if cls not in classes or int(difficult) == 1:\n",
        "            continue\n",
        "        cls_id = classes.index(cls)\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),\n",
        "             float(xmlbox.find('ymax').text))\n",
        "        bb = convert((w, h), b)\n",
        "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
        "    in_file.close()\n",
        "    out_file.close()\n",
        "\n",
        "\n",
        "wd = os.getcwd()\n",
        "wd = os.getcwd()\n",
        "data_base_dir = os.path.join(wd, \"./VOCdevkit/\")\n",
        "if not os.path.isdir(data_base_dir):\n",
        "    os.mkdir(data_base_dir)\n",
        "work_sapce_dir = os.path.join(data_base_dir, \"VOC2012/\")\n",
        "if not os.path.isdir(work_sapce_dir):\n",
        "    os.mkdir(work_sapce_dir)\n",
        "annotation_dir = os.path.join(work_sapce_dir, \"Annotations/\")\n",
        "if not os.path.isdir(annotation_dir):\n",
        "    os.mkdir(annotation_dir)\n",
        "clear_hidden_files(annotation_dir)\n",
        "image_dir = os.path.join(work_sapce_dir, \"JPEGImages/\")\n",
        "if not os.path.isdir(image_dir):\n",
        "    os.mkdir(image_dir)\n",
        "clear_hidden_files(image_dir)\n",
        "yolo_labels_dir = os.path.join(work_sapce_dir, \"YOLOLabels/\")\n",
        "if not os.path.isdir(yolo_labels_dir):\n",
        "    os.mkdir(yolo_labels_dir)\n",
        "clear_hidden_files(yolo_labels_dir)\n",
        "yolov5_images_dir = os.path.join(data_base_dir, \"images/\")\n",
        "if not os.path.isdir(yolov5_images_dir):\n",
        "    os.mkdir(yolov5_images_dir)\n",
        "clear_hidden_files(yolov5_images_dir)\n",
        "yolov5_labels_dir = os.path.join(data_base_dir, \"labels/\")\n",
        "if not os.path.isdir(yolov5_labels_dir):\n",
        "    os.mkdir(yolov5_labels_dir)\n",
        "clear_hidden_files(yolov5_labels_dir)\n",
        "yolov5_images_train_dir = os.path.join(yolov5_images_dir, \"train/\")\n",
        "if not os.path.isdir(yolov5_images_train_dir):\n",
        "    os.mkdir(yolov5_images_train_dir)\n",
        "clear_hidden_files(yolov5_images_train_dir)\n",
        "yolov5_images_test_dir = os.path.join(yolov5_images_dir, \"val/\")\n",
        "if not os.path.isdir(yolov5_images_test_dir):\n",
        "    os.mkdir(yolov5_images_test_dir)\n",
        "clear_hidden_files(yolov5_images_test_dir)\n",
        "yolov5_labels_train_dir = os.path.join(yolov5_labels_dir, \"train/\")\n",
        "if not os.path.isdir(yolov5_labels_train_dir):\n",
        "    os.mkdir(yolov5_labels_train_dir)\n",
        "clear_hidden_files(yolov5_labels_train_dir)\n",
        "yolov5_labels_test_dir = os.path.join(yolov5_labels_dir, \"val/\")\n",
        "if not os.path.isdir(yolov5_labels_test_dir):\n",
        "    os.mkdir(yolov5_labels_test_dir)\n",
        "clear_hidden_files(yolov5_labels_test_dir)\n",
        "\n",
        "train_file = open(os.path.join(wd, \"yolov5_train.txt\"), 'w')\n",
        "test_file = open(os.path.join(wd, \"yolov5_val.txt\"), 'w')\n",
        "train_file.close()\n",
        "test_file.close()\n",
        "train_file = open(os.path.join(wd, \"yolov5_train.txt\"), 'a')\n",
        "test_file = open(os.path.join(wd, \"yolov5_val.txt\"), 'a')\n",
        "list_imgs = os.listdir(image_dir)  # list image files\n",
        "prob = random.randint(1, 100)\n",
        "print(\"Probability: %d\" % prob)\n",
        "for i in range(0, len(list_imgs)):\n",
        "    path = os.path.join(image_dir, list_imgs[i])\n",
        "    if os.path.isfile(path):\n",
        "        image_path = image_dir + list_imgs[i]\n",
        "        voc_path = list_imgs[i]\n",
        "        (nameWithoutExtention, extention) = os.path.splitext(os.path.basename(image_path))\n",
        "        (voc_nameWithoutExtention, voc_extention) = os.path.splitext(os.path.basename(voc_path))\n",
        "        annotation_name = nameWithoutExtention + '.xml'\n",
        "        annotation_path = os.path.join(annotation_dir, annotation_name)\n",
        "        label_name = nameWithoutExtention + '.txt'\n",
        "        label_path = os.path.join(yolo_labels_dir, label_name)\n",
        "    prob = random.randint(1, 100)\n",
        "    print(\"Probability: %d\" % prob)\n",
        "    if (prob < TRAIN_RATIO):  # train dataset\n",
        "        if os.path.exists(annotation_path):\n",
        "            train_file.write(image_path + '\\n')\n",
        "            convert_annotation(nameWithoutExtention)  # convert label\n",
        "            copyfile(image_path, yolov5_images_train_dir + voc_path)\n",
        "            copyfile(label_path, yolov5_labels_train_dir + label_name)\n",
        "    else:  # test dataset\n",
        "        if os.path.exists(annotation_path):\n",
        "            test_file.write(image_path + '\\n')\n",
        "            convert_annotation(nameWithoutExtention)  # convert label\n",
        "            copyfile(image_path, yolov5_images_test_dir + voc_path)\n",
        "            copyfile(label_path, yolov5_labels_test_dir + label_name)\n",
        "train_file.close()\n",
        "test_file.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_TvVJsDHOet"
      },
      "outputs": [],
      "source": [
        "# Classes\n",
        "nc: 20  # number of classes\n",
        "names: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',\n",
        "        'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']  # class names\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/train.py"
      ],
      "metadata": {
        "id": "1N_7Q9BlDeNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d2c7ab8-dc82-4005-d24b-e00265aa2b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=/content/yolov5/models/yolov5s_test.yaml, data=/content/yolov5/data/VOC_test.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-168-gec2b853 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     67425  models.yolo.Detect                      [20, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s_test summary: 214 layers, 7073569 parameters, 7073569 gradients, 16.1 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5/yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/VOC/labels/train2007.cache... 16551 images, 0 backgrounds, 0 corrupt: 100% 16551/16551 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/VOC/labels/test2007.cache... 4952 images, 0 backgrounds, 0 corrupt: 100% 4952/4952 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.99 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to yolov5/runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/2      3.46G    0.06026    0.03491    0.04495         32        640: 100% 1035/1035 [04:15<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 155/155 [00:38<00:00,  4.05it/s]\n",
            "                   all       4952      12032       0.66      0.665      0.701      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/2      6.89G    0.04456    0.03049    0.02016         27        640: 100% 1035/1035 [04:10<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 155/155 [00:35<00:00,  4.31it/s]\n",
            "                   all       4952      12032      0.703      0.708      0.755      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/2      6.89G    0.03954    0.03045    0.01613         39        640: 100% 1035/1035 [04:16<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 155/155 [00:35<00:00,  4.39it/s]\n",
            "                   all       4952      12032      0.764      0.738      0.797      0.507\n",
            "\n",
            "3 epochs completed in 0.243 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating yolov5/runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s_test summary: 157 layers, 7064065 parameters, 0 gradients, 15.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 155/155 [00:42<00:00,  3.62it/s]\n",
            "                   all       4952      12032      0.764      0.738      0.797      0.506\n",
            "             aeroplane       4952        285      0.827      0.814       0.84      0.466\n",
            "               bicycle       4952        337      0.871      0.739      0.866      0.543\n",
            "                  bird       4952        459      0.692      0.678      0.713       0.42\n",
            "                  boat       4952        263      0.687      0.563      0.639      0.332\n",
            "                bottle       4952        469      0.631       0.77      0.764      0.472\n",
            "                   bus       4952        213      0.814      0.793      0.874      0.655\n",
            "                   car       4952       1201      0.791      0.893      0.919      0.637\n",
            "                   cat       4952        358      0.834      0.759      0.835       0.57\n",
            "                 chair       4952        756      0.572      0.647      0.654      0.395\n",
            "                   cow       4952        244      0.782       0.78      0.851       0.56\n",
            "           diningtable       4952        206       0.72      0.655      0.732      0.462\n",
            "                   dog       4952        489      0.809      0.651        0.8      0.518\n",
            "                 horse       4952        348      0.866      0.836      0.898      0.584\n",
            "             motorbike       4952        325      0.841      0.769      0.857       0.53\n",
            "                person       4952       4528       0.85      0.816      0.892      0.571\n",
            "           pottedplant       4952        480      0.604      0.541      0.548      0.278\n",
            "                 sheep       4952        242      0.853      0.731       0.86       0.55\n",
            "                  sofa       4952        239      0.617      0.707      0.724      0.502\n",
            "                 train       4952        282      0.863      0.791       0.85      0.526\n",
            "             tvmonitor       4952        308      0.753      0.818      0.825      0.558\n",
            "Results saved to \u001b[1myolov5/runs/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "dNZRUNVhDeKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d1d5a7-e546-4e03-a0b1-4387018c691a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.105-py3-none-any.whl (586 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.5/586.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Collecting sentry-sdk (from ultralytics)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: sentry-sdk, ultralytics\n",
            "Successfully installed sentry-sdk-1.23.1 ultralytics-8.0.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3t7U5NzmDeHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QfI-idbvDeE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZoOiW00KlBG"
      },
      "source": [
        "# SSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-1txeomKlr-"
      },
      "outputs": [],
      "source": [
        "from gluoncv.data import VOCDetection\n",
        "\n",
        "train_dataset = VOCDetection(splits=[(2012, 'train')])\n",
        "val_dataset = VOCDetection(splits=[(2007, 'val')])\n",
        "\n",
        "print('Training images:', len(train_dataset))\n",
        "print('Validation images:', len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVA0tkNXS6yt"
      },
      "outputs": [],
      "source": [
        "from gluoncv.data.transforms import presets\n",
        "from gluoncv import utils\n",
        "from mxnet import nd\n",
        "\n",
        "width, height = 512, 512  # suppose we use 512 as base training size\n",
        "train_transform = presets.ssd.SSDDefaultTrainTransform(width, height)\n",
        "val_transform = presets.ssd.SSDDefaultValTransform(width, height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIHIwfmeTC6B"
      },
      "outputs": [],
      "source": [
        "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
        "from mxnet.gluon.data import DataLoader\n",
        "\n",
        "batch_size = 20\n",
        "num_workers = 4\n",
        "\n",
        "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
        "train_loader = DataLoader(\n",
        "    train_dataset.transform(train_transform),\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    batchify_fn=batchify_fn,\n",
        "    last_batch='rollover',\n",
        "    num_workers=num_workers)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset.transform(val_transform),\n",
        "    batch_size,\n",
        "    shuffle=False,\n",
        "    batchify_fn=batchify_fn,\n",
        "    last_batch='keep',\n",
        "    num_workers=num_workers)\n",
        "\n",
        "for ib, batch in enumerate(train_loader):\n",
        "    if ib > 3:\n",
        "        break\n",
        "    print('data:', batch[0].shape, 'label:', batch[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Acs5CzljTRuw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aea93a4ab8b04d8f86c188d02c4e4add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fa2c766b41c4cd48493673b1db8583c",
              "IPY_MODEL_fa39a12f34a54c49ac06965714e77198",
              "IPY_MODEL_1747fbe6f82a4e0a810f54559f246ed3"
            ],
            "layout": "IPY_MODEL_f32efdfdd37b4843bf426febdaac3d90"
          }
        },
        "2fa2c766b41c4cd48493673b1db8583c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b016daf67bc14d59bf37ad45735e865d",
            "placeholder": "​",
            "style": "IPY_MODEL_e40564769b92434abb825a83ac811097",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "fa39a12f34a54c49ac06965714e77198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75fad9f08874482d97330066fa1c037d",
            "max": 4133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cff9ef37353c44f5821d03c58aa6527a",
            "value": 4133
          }
        },
        "1747fbe6f82a4e0a810f54559f246ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67edc3ff20b84233a3b996008d2bf5a9",
            "placeholder": "​",
            "style": "IPY_MODEL_75c9d26e85d54ef480b7f67d15765a5d",
            "value": " 4.13k/4.13k [00:00&lt;00:00, 228kB/s]"
          }
        },
        "f32efdfdd37b4843bf426febdaac3d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b016daf67bc14d59bf37ad45735e865d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40564769b92434abb825a83ac811097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75fad9f08874482d97330066fa1c037d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff9ef37353c44f5821d03c58aa6527a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67edc3ff20b84233a3b996008d2bf5a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c9d26e85d54ef480b7f67d15765a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e37c2f3c6a0542be88cbf7d3a1d361d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fe2332b0b16415292f099bc1193fbd1",
              "IPY_MODEL_21669dd0d5454956a1c27086551726fb",
              "IPY_MODEL_2a47e10d9fea42baaff52e8c9620b780"
            ],
            "layout": "IPY_MODEL_2e151d67436247e9bef9ddd9d4ecac7d"
          }
        },
        "0fe2332b0b16415292f099bc1193fbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f6b3696f304c59ba217d0ae34b8310",
            "placeholder": "​",
            "style": "IPY_MODEL_6142c1f5f1e14672ba5787a10095764e",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "21669dd0d5454956a1c27086551726fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71f8bfd34aa1491c8793d75731ed9a4a",
            "max": 26021147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_312de1127db54816aa03e9388a3cfcbb",
            "value": 26021147
          }
        },
        "2a47e10d9fea42baaff52e8c9620b780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e0ddf18d69434084a6ca8e7051b248",
            "placeholder": "​",
            "style": "IPY_MODEL_62e7a146254d4770af584a0e408f13b7",
            "value": " 26.0M/26.0M [00:00&lt;00:00, 192MB/s]"
          }
        },
        "2e151d67436247e9bef9ddd9d4ecac7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f6b3696f304c59ba217d0ae34b8310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6142c1f5f1e14672ba5787a10095764e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71f8bfd34aa1491c8793d75731ed9a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "312de1127db54816aa03e9388a3cfcbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28e0ddf18d69434084a6ca8e7051b248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e7a146254d4770af584a0e408f13b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a05a5cf83d96474aafbe98238a308ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2807487061714ef7be36b5e603033022",
              "IPY_MODEL_52561bc49e1d4e9da403a1e58016108c",
              "IPY_MODEL_47bf388637fc4730a3f39e0039b71a30"
            ],
            "layout": "IPY_MODEL_5570ac7f0a894ebe9fe0676501c047c7"
          }
        },
        "2807487061714ef7be36b5e603033022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6028974c7d1641189825e8937bd7b4b1",
            "placeholder": "​",
            "style": "IPY_MODEL_c79c635fe6a940f5883bd39093f37f45",
            "value": "Downloading (…)rocessor_config.json: 100%"
          }
        },
        "52561bc49e1d4e9da403a1e58016108c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b465c30427449c8ead21b880a55260",
            "max": 275,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0feeab7a1c5847d9a232fa5d92524118",
            "value": 275
          }
        },
        "47bf388637fc4730a3f39e0039b71a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21832acae4e4900bff9619e45a9bfa0",
            "placeholder": "​",
            "style": "IPY_MODEL_5ded7f2574b7488ea9d3a3a7a72d9aee",
            "value": " 275/275 [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "5570ac7f0a894ebe9fe0676501c047c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6028974c7d1641189825e8937bd7b4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79c635fe6a940f5883bd39093f37f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7b465c30427449c8ead21b880a55260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0feeab7a1c5847d9a232fa5d92524118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21832acae4e4900bff9619e45a9bfa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ded7f2574b7488ea9d3a3a7a72d9aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}